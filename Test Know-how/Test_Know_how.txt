
1. 하이퍼 파라미터
알아서 학습되는 것이 아닌 사용자가 직접 지정하는 값
최적화 알고리즘, 학습률, 배치 크기, 에포크 수, 가중치 초기화 방법, 드롭아웃 비율 등

2. 모델 튜닝
모델의 성능을 향상 시키기 위해 하이퍼 파라미터를 최적화 하는 것
테스트 세트로 모델 튜닝 -> 테스트 세트의 정보가 유출됨 -> 일반화 성능(generalization performance) 왜곡

3. 검증세트(Validation set)
모델을 튜닝하는 용도의 세트, 검증세트
훈련 세트에서 만듬 ex) 전체(100) = 훈련(60)+검증(20)+테스트(20)

4. 데이터 전처리(data preprocessing)

스케일: 특성이 가지고있는 범위
경사하강법은 기본적으로 스케일에 민감한 알고리즘
따라서 스케일을 맞추는 등의 전처리가 필요함

표준화: 스케일 조정방법 중 하나
(특성값-평균)/표준편차
이때 훈련세트의 평균과 표준편차를 사용해서 스케일 조정 비율이 어긋나는것을 방지

5. 과대적합 (overfitting)
훈련 -> 검증 -> 튜닝 -> 다시 or 테스트 
이러한 과정에서 모델이 훈련에서는 좋은 성능을 발하지만
검증세트에 대해서는 낮은 성능을 내는 경우 
= 분산이 크다

샘플 더 확보, 가중치 제한, 복잡도 낮추기

6. 과소적합(underfitting)
훈련세트와 검증세트에서의 성능차이가 크지 않지만 둘다 낮은경우
=편향이 크다

복잡도 높은 모델 사용, 가중치 규제 완화

이때 분산과 편향 사이에 트레이드 오프 존재

7. 규제
가중치를 제한하는것 (가중치 변화를 제한, 방법이 여러개임)
모델의 일반화 성능을 높일 수 있다.

8. 교차검증
훈련데이터를 임의의 폴드로 나누어서 각각을 검증세트로 한 튜닝을 여러번 진행
이때 검증세트를 포함해서 데이터 전처리를 하게되면 검증세트가 누설되기 때문에,
각각의 폴드마다 훈련세트와 분리하여 전처리를 진행,
이와 관련된 gpt와의 문답을 아래에 첨부


--------------------------------------------------------------------------
Q: 
검증폴드가 표준화 전처리 단계에서 누설된다는게 무슨 뜻이야?

A: 
검증폴드가 표준화(Standardization) 전처리 단계에서 누설(Leakage)된다는 것은, 
검증 데이터의 통계량을 학습 데이터에서 계산하여 사용하여, 검증 데이터가 모델 학습에 영향을 미친다는 것을 의미합니다.

표준화는 평균이 0이고, 표준편차가 1인 분포로 변환하는 과정을 말합니다. 

이러한 전처리 과정에서 학습 데이터와 검증 데이터의 통계량(평균, 표준편차)을 동시에 계산하게 되면, 
검증 데이터에 대한 정보가 모델 학습에 누설될 수 있습니다.

이러한 누설을 방지하기 위해서는, 전처리 과정에서 학습 데이터와 검증 데이터를 분리하고, 학습 데이터에서 계산된 통계량만을 사용하여 검증 데이터를 전처리해야 합니다. 

이를 위해 전처리 과정을 Pipeline과 같은 방법으로 구성하면, 검증 데이터가 학습 데이터에 누설되는 것을 방지할 수 있습니다.




Q:
그런데 교차검증 방법에서는 검증세트가 곧 훈련세트의 일부가 되고, 어떨때는 검증세트가 되는거잖아

A:
교차검증 방법에서는 검증세트가 훈련세트의 일부가 되는 경우가 있습니다. 

k-fold 교차검증에서는 전체 데이터셋을 k개의 fold로 분할한 후, 한 fold를 검증 데이터로 사용하고, 
나머지 fold를 학습 데이터로 사용하는 방식입니다. 

이 경우, 검증 데이터는 훈련 데이터의 일부가 됩니다.

그러나 교차검증에서 검증 데이터가 학습 데이터의 일부가 되더라도, 검증 데이터는 항상 학습 데이터와 분리되어야 합니다. 
즉, 검증 데이터는 학습 데이터에서 따로 분리하여 사용되어야 하며, 검증 데이터에 대한 전처리는 학습 데이터에서 추출된 통계량만을 사용해야 합니다.

따라서, k-fold 교차검증에서도 전처리 과정에서 검증 데이터에 대한 정보 누설을 방지하기 위해서, 
전처리 과정을 Pipeline 등으로 구성하여 학습 데이터와 검증 데이터를 분리하고, 학습 데이터에서 추출된 통계량만을 사용하여 전처리해야 합니다.




Q: 
그럼 만약에 5개의 폴드로 나눈다고하면 전처리또한 5번을 시행해야하는거야?

A:
네, 맞습니다. k-fold 교차검증을 수행할 때, 전체 데이터셋을 k개의 fold로 나누게 되면, 각각의 fold마다 전처리를 수행해야 합니다. 

이는 각각의 fold가 학습 데이터와 검증 데이터가 될 수 있기 때문입니다.

따라서, k-fold 교차검증을 수행할 때는 전처리를 각각의 fold마다 수행해야 하며, 이를 효율적으로 수행하기 위해서는 Pipeline 등의 도구를 사용하는 것이 좋습니다.

이를 통해, 각각의 fold에서 전처리를 자동화하고, 검증 데이터의 정보 누설을 방지할 수 있습니다.




Q: 
그럼 검증세트가 되는 폴드의 순서도 모델의 학습에 영향을 미치는거 아니야? 왜냐하면 전처리가 여러번이고 그 순서가 달라진다는거니까

A:
네, 검증세트가 되는 폴드의 순서도 모델의 학습에 영향을 미칠 수 있습니다.

만약, 데이터셋에서 시간 정보가 중요한 역할을 하는 경우, 시간순으로 데이터셋을 분할하고 교차검증을 수행하는 것이 좋습니다. 

이렇게 하면, 학습 데이터와 검증 데이터가 시간적으로 서로 겹치지 않도록 할 수 있습니다.

하지만, 일반적으로는 교차검증을 수행하는데 있어서, 각 fold의 순서가 모델의 학습에 큰 영향을 미치지는 않습니다. 

이는 k-fold 교차검증에서, fold를 무작위로 섞어서 사용하기 때문입니다. 

따라서, 전처리 과정에서 수행하는 데이터 순서를 섞는 등의 무작위성이 있을 경우, 검증세트가 되는 폴드의 순서가 모델의 학습에 큰 영향을 미치지는 않습니다.

하지만, 전처리 과정에서 무작위성이 없는 경우, 예를 들어 정규화와 같은 경우, 검증세트가 되는 폴드의 순서가 모델의 학습에 영향을 미칠 수 있습니다. 

이러한 경우, 학습 데이터를 섞거나 무작위로 추출하는 등의 방법을 사용하여, 검증세트가 되는 폴드의 순서에 따른 영향을 최소화할 수 있습니다.




